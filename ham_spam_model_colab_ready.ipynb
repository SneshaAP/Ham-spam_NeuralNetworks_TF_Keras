{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bef72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spam vs Ham Classifier using Neural Networks (Keras)\n",
    "\n",
    "Author: Snesha Aamalepatil\n",
    "Description:\n",
    "    A simple neural network built using Keras and TensorFlow to classify SMS messages\n",
    "    as spam or ham (not spam). Text preprocessing uses CountVectorizer, and the\n",
    "    model uses Dense layers with dropout regularization.\n",
    "\n",
    "Dataset:\n",
    "    SMS Spam Collection Dataset from UCI Repository or equivalent.\n",
    "    Path in script: /content/archive (6).zip\n",
    "\n",
    "License: MIT (or any other license you prefer)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import scikit-learn and Keras components\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load SMS spam collection dataset\n",
    "data = pd.read_csv('/content/archive (6).zip', encoding='latin-1')\n",
    "\n",
    "# Show data structure\n",
    "data.info()\n",
    "\n",
    "# Remove unnecessary columns and keep only 'v1' (label) and 'v2' (message)\n",
    "data = data.iloc[:, :2]\n",
    "data.head()\n",
    "\n",
    "# Separate message text and labels\n",
    "messages = data[\"v2\"].tolist()\n",
    "labels = data[\"v1\"].tolist()\n",
    "\n",
    "# Split the dataset into training and test sets (80/20)\n",
    "x_train, x_test, y_train, y_test = train_test_split(messages, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print sizes\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))\n",
    "\n",
    "# Vectorize the text using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "x_train_vectorized = vectorizer.fit_transform(x_train)\n",
    "x_test_vectorized = vectorizer.transform(x_test)\n",
    "\n",
    "# Convert 'spam' to 1 and 'ham' to 0\n",
    "y_train = [1 if label == 'spam' else 0 for label in y_train]\n",
    "y_test = [1 if label == 'spam' else 0 for label in y_test]\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Build a simple neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='tanh', input_shape=(x_train_vectorized.shape[1],)))\n",
    "model.add(Dropout(0.3))  # Regularization\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Show model architecture\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "x_train_vectorized.sort_indices()  # Ensures indexing is correct for sparse tensors\n",
    "history = model.fit(x_train_vectorized, y_train, epochs=10, batch_size=32, validation_data=(x_test_vectorized, y_test))\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Predict a new sample message\n",
    "new_message = \"let us go out\"\n",
    "new_message_vectorized = vectorizer.transform([new_message])\n",
    "prediction = model.predict(new_message_vectorized)[0][0]\n",
    "\n",
    "if prediction > 0.5:\n",
    "    print(\"Predicted Spam\")\n",
    "else:\n",
    "    print(\"Predicted Ham\")\n",
    "\n",
    "# Display prediction probabilities\n",
    "print(model.predict(new_message_vectorized))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
